{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa540254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2aed14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3941/3317488320.py:1: DtypeWarning: Columns (26,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('final_wec_data.csv')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('final_wec_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dda97779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_for_ml(df):\n",
    "\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    df = data[data['year'] >= 2017].reset_index(drop=True)\n",
    "    # Dropping data from prior to 2017 as driver_ratings data was not available\n",
    "    df = df.drop(['lap_number', 'car_number', 'lap_number', 'driver_number', 'lap_time', 'elapsed', 'hour', 's1_large', 's2_large', 's3_large', 'driver_name', 'pit_time', 'group', 'team', 'manufacturer', 'season', 'vehicle', 'team_no','lap_time_ms', 'engine', 'driver_stint',\n",
    "           'team_stint', 'team_stint_no', 'interval_ms', 'interval', 'elapsed_ms', 'position', 'gap', 'elapsed_s'], axis=1)\n",
    "    # Initial columns dropped because not needed/not useable for modeling. Remaining columns will be further assessed \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adbb9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_for_ml(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b10867f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixing_kept_cols(df):\n",
    "\n",
    "    df = df[df['class']!='INNOVATIVE CAR']\n",
    "#     removing the innovative class to eliminate outlier data\n",
    "    \n",
    "    df = df[df['crossing_finish_line_in_pit']==0]\n",
    "#     Filtering out rows where the lap ended in the pit lane (commonly known as an in-lap). \n",
    "# In theory this data could be useful for the model, under normal circumstances an in-lap would be run on old tires. A driver who can run a faster in-lap than their rivals\n",
    "# may be able to gain positions or time on a competitor and thus suggested a more skilled driver. However a car that has had an issue on track will have an abnormally slow in-lap as it limps back to the pitlane.\n",
    "# The in-lap data complicates the process of trimming outliers from the lap time data. Since only ~6% of records were in-laps we will simply drop these records\n",
    "    \n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "#    Dropping any rows with missing values in remaining data\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c3c11af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fixing_kept_cols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30999e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f72f0ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trim_outliers(df):\n",
    "    grouped = df.groupby(['class', 'circuit'])\n",
    "    for key, group in grouped:\n",
    "        IQR = np.percentile(group['lap_time_s'], 75) - np.percentile(group['lap_time_s'], 25)\n",
    "        u_limit = np.percentile(group['lap_time_s'], 75) + 1*IQR\n",
    "#         l_limit = np.percentile(group['lap_time_s'], 25) - 1.5*IQR\n",
    "#         print(key, 'IQR: ', IQR, 'u_lim: ', u_limit, 'l_lim: ', l_limit)\n",
    "        group = group[group['lap_time_s'] < u_limit]\n",
    "        if 'new_df' in locals():\n",
    "            new_df = pd.concat([new_df, group])\n",
    "        else:\n",
    "            new_df = group.reset_index(drop=True)\n",
    "        \n",
    "    return new_df\n",
    "\n",
    "# Common practice is to remove records based on both the upper and lower limits. Given the type of data we're dealing with it makes sense to only trim upper-limit outliers\n",
    "# This will remove laps where a car crashed, broke down, or was otherwise delayed on track. This will also serve to remove laps run under slowzones, FCY, or Safety car procedures since we do not have data to indicate those situations.\n",
    "#The removed print statement would show the IQR and limit values for each circuit/class pairing for checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "620dc0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = trim_outliers(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046750dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12f0ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_df(df):\n",
    "    cont_nums = df.select_dtypes('number')\n",
    "    cont_nums = cont_nums.drop(['lap_improvement', 'crossing_finish_line_in_pit', 's1_improvement', 's2_improvement', 's3_improvement', 'year', 'round', 'driver_stint_no', 'class_position'], axis=1)\n",
    "    \n",
    "    disc_nums = df[['lap_improvement', 'crossing_finish_line_in_pit', 's1_improvement', 's2_improvement', 's3_improvement', 'year', 'round', 'driver_stint_no', 'class_position']]\n",
    "    \n",
    "    obs = data.select_dtypes(object).drop('rating', axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    target = df['rating']\n",
    "    \n",
    "    return cont_nums, disc_nums, obs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee21b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_nums, disc_nums, obs, target = separate_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84cf86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48f64913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_obs(obs):\n",
    "    class_one_hot = pd.get_dummies(obs['class'], prefix='class')\n",
    "    circuit_one_hot = pd.get_dummies(obs['circuit'], prefix='circuit')\n",
    "    \n",
    "    ob_feats = pd.concat([class_one_hot, circuit_one_hot], axis=1)\n",
    "    \n",
    "    return ob_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c52bff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_feats = encode_obs(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa095e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5acaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scaled_sets(df):\n",
    "    from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "    \n",
    "    scales = []\n",
    "    \n",
    "    s_scaler = StandardScaler()\n",
    "    num_s_scal = s_scaler.fit_transform(df)\n",
    "    num_s_scal = pd.DataFrame(num_s_scal)\n",
    "    num_s_scal.columns = num_s_scal.columns.astype(str)\n",
    "    num_s_scal.name = 'StandardScaler'\n",
    "    scales.append(num_s_scal)\n",
    "    \n",
    "    mm_scaler = MinMaxScaler()\n",
    "    num_mm_scal = mm_scaler.fit_transform(df)\n",
    "    num_mm_scal = pd.DataFrame(num_mm_scal)\n",
    "    num_mm_scal.columns = num_mm_scal.columns.astype(str)\n",
    "    num_mm_scal.name = 'MinMaxScaler'\n",
    "    scales.append(num_mm_scal)\n",
    "    \n",
    "    abs_scaler = MaxAbsScaler()\n",
    "    num_abs_scal = abs_scaler.fit_transform(df)\n",
    "    num_abs_scal = pd.DataFrame(num_abs_scal)\n",
    "    num_abs_scal.columns = num_abs_scal.columns.astype(str)\n",
    "    num_abs_scal.name = 'MaxAbsScaler'\n",
    "    scales.append(num_abs_scal)\n",
    "    \n",
    "    \n",
    "    return scales\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98656b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = make_scaled_sets(cont_nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43441c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_nums = disc_nums.reset_index(drop=True)\n",
    "ob_feats = ob_feats.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0fb336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = pd.concat([scales[0], disc_nums, ob_feats], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state = 55)\n",
    "# # Concatenating features and Making a split for initial testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ffa29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a4a998b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8952385275293904\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Training/fitting an initial run of the RandomForest Classifiier for baseline testing and for parameter tuning\n",
    "\n",
    "# Initial model run resulted in decent accuracy but we will use Hyperparameter tuning to improve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d59998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_tuning_rfc(X_train, y_train):\n",
    "    param_grid_rfc = {'n_estimators': [100, 200, 300], 'max_depth': [5, 10, 15], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['sqrt', 'log2']}\n",
    "    rfc = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(rfc, param_grid=param_grid_rfc, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    rfc_best_params = grid_search.best_params_\n",
    "    \n",
    "    \n",
    "    #print the best parameters and score\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "    return rfc_best_params\n",
    "\n",
    "# # Running multiple loops of the model to find the optimal set of model parameters to maximize model accuracy.\n",
    "# # Using the GridSearchCV function will allow us to test multiple iterations of the model each with a different set of parameters. The function compares the accuracy score of each iteration\n",
    "# # and will finally report the best score and the parameter settings used to acheive this. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d53374",
   "metadata": {},
   "outputs": [],
   "source": [
    " rfc_best_params = hyper_tuning_rfc(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d6124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# # An initial run of the KNN Classifier on the same training data as the RandomForest model reports much higher accuracy\n",
    "\n",
    "# # Hyper-paramter tuning will be run for this model as well in an attempt to maximize our models accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_tuning_knn(X_train, y_train):\n",
    "    param_grid_knn = {'n_neighbors': (1,10, 1), 'leaf_size': (20,40,1), 'p': (1,2), 'weights': ('uniform', 'distance'), 'metric': ('minkowski', 'chebyshev')}\n",
    "    knn = KNeighborsClassifier()\n",
    "    grid_search = GridSearchCV(knn, param_grid=param_grid_knn, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    knn_best_params = grid_search.best_params_\n",
    "    \n",
    "    \n",
    "    #print the best parameters and score\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "    return knn_best_params\n",
    "\n",
    "# # Running multiple loops of the model to find the optimal set of model parameters to maximize model accuracy\n",
    "\n",
    "# # ***After running the grid search function through the model hyperparameters we have acheived a best score of ~84% accuracy. The output best parameters wil be used for this model from here on out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9877db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_params = hyper_tuning_knn(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589843b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d308a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [RandomForestClassifier(), KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df455efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b1c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models_scales(scales, disc_nums, ob_feats, models, knn_best_params, rfc_best_params, target):\n",
    "    for model in models:\n",
    "        model_name = type(model).__name__\n",
    "        for scale in scales:\n",
    "            scale_name = scale.name\n",
    "            features = pd.concat([scale, disc_nums, ob_feats], axis=1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=55)\n",
    "            if model_name == 'KNeighborsClassifier':\n",
    "                clf = KNeighborsClassifier(**knn_best_params)\n",
    "            elif model_name == 'RandomForestClassifier':\n",
    "                clf = RandomForestClassifier(**rfc_best_params)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f\"{model_name} : {scale_name} : {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a427a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models_scales(scales, disc_nums, ob_feats, models, knn_best_params, rfc_best_params, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddad844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1371048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the reults from the test_models_scales function we now have the optimal model type, scaler type, and best parameters for the model.\n",
    "# Now we can fit the model one last time to export for future use.\n",
    "\n",
    "driver_ratings_model = KNeighborsClassifier(**knn_best_params)\n",
    "features = pd.concat([scales[0], disc_nums, ob_feats], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=55)\n",
    "driver_ratings_model.fit(X_train, y_train)\n",
    "\n",
    "import joblib\n",
    "   \n",
    "# Save the model as a pickle in a file\n",
    "joblib.dump(driver_ratings_model, 'driver_ratings_model.pkl')\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
