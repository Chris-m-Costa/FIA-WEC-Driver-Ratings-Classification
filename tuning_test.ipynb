{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac374ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd395f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1520/3317488320.py:1: DtypeWarning: Columns (26,31,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('final_wec_data.csv')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('final_wec_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a2d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.drop('Unnamed: 0', axis=1)\n",
    "# #  Dropping the extra index col\n",
    "\n",
    "# data = data[data['year'] >= 2017].reset_index(drop=True)\n",
    "# # # Dropping data from prior to 2017 as driver_ratings data was not available\n",
    "\n",
    "# data = data.drop(['lap_number', 'car_number', 'lap_number', 'driver_number', 'lap_time', 'elapsed', 'hour', 's1_large', 's2_large', 's3_large', 'driver_name', 'pit_time', 'group', 'team', 'manufacturer', 'season', 'vehicle', 'team_no','lap_time_ms', 'engine', 'driver_stint',\n",
    "#            'team_stint', 'team_stint_no', 'interval_ms', 'interval', 'elapsed_ms', 'position', 'gap', 'elapsed_s', ], axis=1)\n",
    "# # Initial columns dropped because not needed/not useable for modeling. Remaining columns will be further assessed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ad4d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_for_ml(df):\n",
    "\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    df = data[data['year'] >= 2017].reset_index(drop=True)\n",
    "    # Dropping data from prior to 2017 as driver_ratings data was not available\n",
    "    df = df.drop(['lap_number', 'car_number', 'lap_number', 'driver_number', 'lap_time', 'elapsed', 'hour', 's1_large', 's2_large', 's3_large', 'driver_name', 'pit_time', 'group', 'team', 'manufacturer', 'season', 'vehicle', 'team_no','lap_time_ms', 'engine', 'driver_stint',\n",
    "           'team_stint', 'team_stint_no', 'interval_ms', 'interval', 'elapsed_ms', 'position', 'gap', 'elapsed_s'], axis=1)\n",
    "    # Initial columns dropped because not needed/not useable for modeling. Remaining columns will be further assessed \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "281fc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_for_ml(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6394343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70cc9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixing_kept_cols(df):\n",
    "    df['crossing_finish_line_in_pit'] = df['crossing_finish_line_in_pit'].fillna(0)\n",
    "    df['crossing_finish_line_in_pit'] = df['crossing_finish_line_in_pit'].replace('B', 1)\n",
    "#   B represents a car crossing the start/finish line in pitlane, NaN means the car was on track. Values are replaced with binary 0 for on-track, 1 for in-pit\n",
    "\n",
    "    df = df[df['class']!='INNOVATIVE CAR']\n",
    "#     removing the innovative class to eliminate outlier data\n",
    "    \n",
    "    \n",
    "    df['circuit'] = df['circuit'].replace({'SPA FRANCORCHAMPS':'Spa', 'BAHRAIN INTERNATIONAL CIRCUIT':'Bahrain', 'FUJI SPEEDWAY':'Fuji', 'SHANGHAI INTERNATIONAL CIRCUIT':'Shanghai', 'CIRCUIT OF THE AMERICAS':'COTA',\n",
    "    'AUTODROMO HERMANOS RODRIGUEZ':'Mexico', 'LE MANS 2018':'Le Mans', 'SPA FRANCORCHAMPS 2019':'Spa','LE MANS 2019':'Le Mans', 'BAHRAIN INTERNATIONAL CIRCUIT 2019': 'Bahrain',\n",
    "    'BAHRAIN INTERNATIONAL CIRCUIT 2020':'Bahrain', 'AUTODROMO DO ALGARVE':'Portimao', 'AUTODROMO NAZIONALE DI MONZA':'Monza', 'BAHRAIN INTERNATIONAL CIRCUIT 6 HOURS':'Bahrain', 'BAHRAIN INTERNATIONAL CIRCUIT 8 HOURS':'Bahrain'})\n",
    "    df['circuit'] = df['circuit'].str.lower() \n",
    "#     Replacing the long-form and/or year appended circuit names with the common-use short versions. Also changes all to lower-case\n",
    "\n",
    "\n",
    "    df = df.drop('flag_at_fl', axis=1)\n",
    "#     data in this column only exists for season 2022, also some value meanings can not be determined.\n",
    "\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    # Dropping NaN values to remove rows with missing data\n",
    "    #12.68% of laps were run by drivers for which we have no rating info\n",
    "    #otherwise only small percentages of nan values exist in other columns \n",
    "    #nans can be safely dropped without significant effect. \n",
    "    \n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d5aa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1520/2614309269.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['circuit'] = df['circuit'].replace({'SPA FRANCORCHAMPS':'Spa', 'BAHRAIN INTERNATIONAL CIRCUIT':'Bahrain', 'FUJI SPEEDWAY':'Fuji', 'SHANGHAI INTERNATIONAL CIRCUIT':'Shanghai', 'CIRCUIT OF THE AMERICAS':'COTA',\n",
      "/tmp/ipykernel_1520/2614309269.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['circuit'] = df['circuit'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "data = fixing_kept_cols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4fb6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d54cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.isna().sum()/len(data)*100\n",
    "\n",
    "#small percentages of nan values can be safely dropped without significant effect. \n",
    "#12.68% of laps were run by a driver for which we have no rating info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a961317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.dropna().reset_index(drop=True)\n",
    "# # Dropping NaN values to remove rows with missing data\n",
    "\n",
    "# #This will be included into the fixing_kept_cols function when the code is refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "287a385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.isna().sum()/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f67d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33af7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a44de13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af5d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b3e699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ada26c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80a4c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['circuit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5a8f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00967a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4538da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs = data.select_dtypes(object).drop('rating', axis=1)\n",
    "\n",
    "# class_one_hot = pd.get_dummies(obs['class'], prefix='class')\n",
    "\n",
    "# circuit_one_hot = pd.get_dummies(obs['circuit'], prefix='circuit')\n",
    "\n",
    "# ob_feats = pd.concat([class_one_hot, circuit_one_hot], axis=1)\n",
    "\n",
    "# ob_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc9f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f61a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6f4e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cont_nums = data.select_dtypes('number')\n",
    "# cont_nums = cont_nums.drop(['lap_improvement', 'crossing_finish_line_in_pit', 's1_improvement', 's2_improvement', 's3_improvement', 'year', 'round', 'driver_stint_no', 'class_position'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "304a2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disc_nums = data[['lap_improvement', 'crossing_finish_line_in_pit', 's1_improvement', 's2_improvement', 's3_improvement', 'year', 'round', 'driver_stint_no', 'class_position']]\n",
    "# disc_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eba852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61f0335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_df(df):\n",
    "    cont_nums = df.select_dtypes('number')\n",
    "    cont_nums = cont_nums.drop(['lap_improvement', 'crossing_finish_line_in_pit', 's1_improvement', 's2_improvement', 's3_improvement', 'year', 'round', 'driver_stint_no', 'class_position'], axis=1)\n",
    "    \n",
    "    disc_nums = df[['lap_improvement', 'crossing_finish_line_in_pit', 's1_improvement', 's2_improvement', 's3_improvement', 'year', 'round', 'driver_stint_no', 'class_position']]\n",
    "    \n",
    "    obs = data.select_dtypes(object).drop('rating', axis=1)\n",
    "\n",
    "    target = df['rating']\n",
    "    \n",
    "    return cont_nums, disc_nums, obs, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d96e948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_obs(obs):\n",
    "    class_one_hot = pd.get_dummies(obs['class'], prefix='class')\n",
    "    circuit_one_hot = pd.get_dummies(obs['circuit'], prefix='circuit')\n",
    "    \n",
    "    ob_feats = pd.concat([class_one_hot, circuit_one_hot], axis=1)\n",
    "    \n",
    "    return ob_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118be6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d68e12d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_nums, disc_nums, obs, target = separate_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7226c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "830dee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_feats = encode_obs(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f73bf5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ob_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af78b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23736442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_scaler = StandardScaler()\n",
    "# num_s_scal = s_scaler.fit_transform(nums)\n",
    "# num_s_scal = pd.DataFrame(num_s_scal)\n",
    "# num_s_scal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8cc648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm_scaler = MinMaxScaler()\n",
    "# num_mm_scal = mm_scaler.fit_transform(nums)\n",
    "# num_mm_scal = pd.DataFrame(num_mm_scal)\n",
    "# num_mm_scal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "469a0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs_scaler = MaxAbsScaler()\n",
    "# num_abs_scal = abs_scaler.fit_transform(nums)\n",
    "# num_abs_scal = pd.DataFrame(num_abs_scal)\n",
    "# num_abs_scal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab30a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scaled_sets(df):\n",
    "    from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "    \n",
    "    scales = []\n",
    "    \n",
    "    s_scaler = StandardScaler()\n",
    "    num_s_scal = s_scaler.fit_transform(df)\n",
    "    num_s_scal = pd.DataFrame(num_s_scal)\n",
    "    num_s_scal.columns = num_s_scal.columns.astype(str)\n",
    "    num_s_scal.name = 'StandardScaler'\n",
    "    scales.append(num_s_scal)\n",
    "    \n",
    "    mm_scaler = MinMaxScaler()\n",
    "    num_mm_scal = mm_scaler.fit_transform(df)\n",
    "    num_mm_scal = pd.DataFrame(num_mm_scal)\n",
    "    num_mm_scal.columns = num_mm_scal.columns.astype(str)\n",
    "    num_mm_scal.name = 'MinMaxScaler'\n",
    "    scales.append(num_mm_scal)\n",
    "    \n",
    "    abs_scaler = MaxAbsScaler()\n",
    "    num_abs_scal = abs_scaler.fit_transform(df)\n",
    "    num_abs_scal = pd.DataFrame(num_abs_scal)\n",
    "    num_abs_scal.columns = num_abs_scal.columns.astype(str)\n",
    "    num_abs_scal.name = 'MaxAbsScaler'\n",
    "    scales.append(num_abs_scal)\n",
    "    \n",
    "    \n",
    "    return scales\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ecdf23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = make_scaled_sets(cont_nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f991f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_s_scal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9570c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_mm_scal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4595dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_abs_scal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e75a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([scales[0], disc_nums, ob_feats], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9124e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9149bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state = 55)\n",
    "# Making a split for testing purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd74f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09066fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# rfc.fit(X_train,y_train)\n",
    "# y_pred = rf.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# # Training/fitting an initial run of the RandomForest Classifiier\n",
    "# #  Accuracy: 0.48788660717485577\n",
    "# #Initial model run resulted in poor accuracy. Hyperparameter tuning can be used to improve the accuracy result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68477f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e62839be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # define the parameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [5, 10, 15],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'max_features': ['sqrt', 'log2'] }\n",
    "\n",
    "# rfc = RandomForestClassifier()\n",
    "# grid_search = GridSearchCV(rfc, param_grid=param_grid, cv=5)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # print the best parameters and score\n",
    "# print(\"Best parameters: \", grid_search.best_params_)\n",
    "# print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "# Best parameters:  {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "# Best score:  0.785742018337664\n",
    "\n",
    "# ***After running the grid search function through the model hyperparameters we have acheived a best score of ~78% accuracy. The output best parameters wil be used for this model from here on out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0059fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hyper_tuning_rfc():\n",
    "#     param_grid_rfc = {'n_estimators': [100, 200, 300], 'max_depth': [5, 10, 15], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['sqrt', 'log2'] }\n",
    "#     rfc = RandomForestClassifier()\n",
    "#     grid_search = GridSearchCV(rfc, param_grid=param_grid_rfc, cv=5)\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "#     rfc_best_params = grid_search.best_params_\n",
    "    \n",
    "    \n",
    "#     #print the best parameters and score\n",
    "#     print(\"Best parameters: \", grid_search.best_params_)\n",
    "#     print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "#     return rfc_best_params\n",
    "\n",
    "# # Running multiple loops of the model to find the optimal set of model parameters to maximize model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45845a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40709c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# knn = KNeighborsClassifier()\n",
    "# knn.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = knn.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# # An initial run of the KNN Classifier on the same training data as the RandomForest model reports much higher accuracy\n",
    "# # Accuracy: 0.7998781493029423\n",
    "# # Hyper-paramter tuning will be run for this model as well in an attempt to maximize our models accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796bb621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7052f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_tuning_knn(X_train, y_train):\n",
    "    param_grid_knn = {'n_neighbors': (1,10, 1), 'leaf_size': (20,40,1), 'p': (1,2), 'weights': ('uniform', 'distance'), 'metric': ('minkowski', 'chebyshev')}\n",
    "    knn = KNeighborsClassifier()\n",
    "    grid_search = GridSearchCV(knn, param_grid=param_grid_knn, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    knn_best_params = grid_search.best_params_\n",
    "    \n",
    "    \n",
    "    #print the best parameters and score\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "    return knn_best_params\n",
    "\n",
    "# Running multiple loops of the model to find the optimal set of model parameters to maximize model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6a2eae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'leaf_size': 20, 'metric': 'minkowski', 'n_neighbors': 1, 'p': 1, 'weights': 'uniform'}\n",
      "Best score:  0.8498700833258669\n"
     ]
    }
   ],
   "source": [
    "knn_best_params = hyper_tuning_knn(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87643bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63d6b66e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (471464264.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [49]\u001b[0;36m\u001b[0m\n\u001b[0;31m    i.replace(:,=)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "knn_best_params = {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
    "\n",
    "for i in knn_best_params:\n",
    "    i.strip('')\n",
    "    i.replace(:,=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306cdac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81e9cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_scales_model(scales):\n",
    "#     for i in range(len(scales)):\n",
    "#         name = scales[i].name\n",
    "#         features = pd.concat([scales[i], disc_nums, ob_feats], axis=1)\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(features, target, random_state = 55)\n",
    "#         rf = RandomForestClassifier(max_depth=15, max_features='sqrt', min_samples_leaf=1, min_samples_split=2, n_estimators=200)\n",
    "#         rf.fit(X_train,y_train)\n",
    "#         y_pred = rf.predict(X_test)\n",
    "#         accuracy = accuracy_score(y_test, y_pred)\n",
    "#         print(name, \"Accuracy:\", accuracy)\n",
    "        \n",
    "        \n",
    "        \n",
    "# ###This function will test the \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d9a2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_scales_model(scales)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
